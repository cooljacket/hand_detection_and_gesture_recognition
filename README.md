# 仓库内容

1. 论文（已公开）
2. 代码（还在整理中）
3. 其它（tex文件之类的，归档备份到github上）


# 关于算法

1. 手部跟踪（tracking）效果很差，那就用检测（detection）来做；
2. 检测的速度很慢（如Faster R-CNN在普通机器上根本无法实时）；
3. 慢是因为候选区域太多，那就利用运动信息来缩小候选区域的个数；
4. 运动信息，简单理解就是“画面里哪些地方有在动”，可以通过背景减去（backgroud subtraction）来获取；
5. 如何根据运动信息生成候选区域？我的解决方法是：聚类。

这五点思路最好结合论文来看才容易清楚，论文里有详细的图解。


另外，在做“背景减去”的时候，由于我的机器的配置太差了，所以没有用现成的很好的算法（如OpenCV的BackgroundSubtractorMOG），而是自己用简陋的帧差法写了。如果条件好的话，可以使用更好的算法来做，不一定要使用帧差法。


# 本文的贡献

我觉得最大的贡献是，利用运动信息来减少手部候选区域的个数，从而大大提高了检测的速度。不过我的算法太简单了，我觉得以前不可能没人想过这样做，然而我在看手势识别的论文的时候，都没看过有人这样做过。但也不敢说是自己的原创，只能说这确实是我自己独立想出来的，至于是不是第一个则不敢乱说。


另外的贡献，除了走通整个应用的流程、顺带提出一个快速收集数据的方法之外，我自己觉得还有一点：**收集了一个手势数据集**（不过这个数据集涉及太多个人隐私，就不公开了）。之所以这样想，是因为在答辩的时候，有位老师问我，你识别的模型是用已有的（ResNet），那你自己的贡献在哪呢？

我个人觉得，在深度学习里，数据和模型的重要性至少是同等的，模型结构用的是已有的，但是没有数据的话，也没法做成功啊。


